# Edge AI Model Quantization & Android Deployment Project

## Overview
Demonstrating Post-Training INT8 Quantization on MobileNetV2, simulating MediaTek NeuroPilot Quantization Tool workflow.

## Key Results
- Model size reduced 70-75% (~14MB â†’ 4MB)
- Faster inference and lower power consumption
- Successfully deployed to Android App using TensorFlow Lite

## Demo Video
https://youtu.be/wTWY3dvKUT8

## Files
- Quantize_MobileNetV2.ipynb: Full quantization code in Colab
- mobilenet_v2_quant_int8.tflite: Quantized model (4MB)

Thank you for viewing!
Doris Hsu
